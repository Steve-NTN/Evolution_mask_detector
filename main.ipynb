{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.2 64-bit ('ga_cnn')",
   "metadata": {
    "interpreter": {
     "hash": "e0994d4ecfe516863ea8b1725b062664255e02ef1f07fa786c945d66fb3d8c91"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import randint\n",
    "from random import choice\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.optimizers import Adam, Adamax\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from imutils import paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_to_gen(n, size_gen):\n",
    "    binary = bin(n)[2:]\n",
    "    gen = [0] * size_gen\n",
    "    start_gen = size_gen - len(binary)\n",
    "    gen[start_gen:] = [int(x) for x in binary]\n",
    "    return gen\n",
    "\n",
    "def decode_gen(gen):\n",
    "    return int('0b' + ''.join(str(i) for i in gen), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Individual:\n",
    "    def __init__(self):\n",
    "        self.epoch = randint(0, 4)                       # epoch\n",
    "        self.input_size = randint(0, 4)                  # input size\n",
    "        self.batch_size = randint(0, 4)                  # batch size\n",
    "        # conv 1st\n",
    "        self.filter_size_1 = randint(0, 8)               # filter size 1\n",
    "        self.kernel_size_1 = randint(0, 2)               # kernel size 1\n",
    "        self.pooling_1 = randint(0, 2)                   # type pooling 1\n",
    "        self.pooling_size_1 = randint(0, 2)              # pooling size 1\n",
    "        self.activation_1 = randint(0, 2)                # type activation 1\n",
    "        self.padding_1 = randint(0, 2)                   # type padding conv 1\n",
    "        # conv 2nd\n",
    "        self.filter_size_2 = randint(0, 8)               # filter size 2\n",
    "        self.kernel_size_2 = randint(0, 2)               # kernel size 2\n",
    "        self.pooling_2 = randint(0, 2)                   # type pooling 2\n",
    "        self.pooling_size_2 = randint(0, 2)              # pooling size 2\n",
    "        self.activation_2 = randint(0, 2)                # type activation 2\n",
    "        self.padding_2 = randint(0, 2)                   # type padding conv 2\n",
    "        # conv 3th\n",
    "        self.filter_size_3 = randint(0, 8)               # filter size 3\n",
    "        self.kernel_size_3 = randint(0, 2)               # kernel size 3\n",
    "        self.pooling_3 = randint(0, 2)                   # type pooling 3\n",
    "        self.pooling_size_3 = randint(0, 2)              # pooling size 3\n",
    "        self.activation_3 = randint(0, 2)                # type activation 3\n",
    "        self.padding_3 = randint(0, 2)                   # type padding conv 3\n",
    "\n",
    "        self.activation_4 = randint(0, 2)                # type activation 4\n",
    "        self.activation_5 = 'softmax'                    # type activation 5\n",
    "        self.dropout_1 = randint(0, 4)                   # dropout size 1\n",
    "        self.dense_1 = randint(0, 8)                     # dense size 1\n",
    "        self.loss_func = randint(0, 2)                   # loss function\n",
    "        self.optimizer = randint(0, 2)                   # optimization type\n",
    "        self.learn_rate = randint(0, 4)                  # learn rate\n",
    "\n",
    "    # Get binary gen\n",
    "    def individual_binary(self):\n",
    "        # init individual with 40 parameter\n",
    "        indiv = np.array([0]*40)\n",
    "\n",
    "        # ______6 bit______|_____________8 bit x 3 = 24 bit____________|_________________10 bit__________________\n",
    "        # epoch|input|batch|filter|kernel|activ|pool |pool_size|padding|dropout|dense|activ|loss_f|optim|learn_r| \n",
    "        # 2 bit|2 bit|2 bit|3 bit |1 bit |1 bit|1 bit|  1 bit  | 1 bit | 2 bit |3 bit|1 bit|1 bit |1 bit| 2 bit |\n",
    "\n",
    "        bit = [2, 2, 2] + [3, 1, 1, 1, 1, 1] * 3 + [2, 3, 1, 1, 1, 2]\n",
    "        param = [self.epoch, self.input_size, self.batch_size, self.filter_size_1, self.kernel_size_1,\n",
    "                 self.pooling_1, self.pooling_size_1, self.activation_1, self.padding_1, self.filter_size_2, \n",
    "                 self.kernel_size_2, self.pooling_2, self.pooling_size_2, self.activation_2, self.padding_2, \n",
    "                 self.filter_size_3, self.kernel_size_3, self.pooling_3, self.pooling_size_3, self.activation_3, \n",
    "                 self.padding_3, self.dropout_1, self.dense_1, self.activation_4, self.loss_func, self.optimizer, \n",
    "                 self.learn_rate]\n",
    "        start = 0\n",
    "        for i in range(len(param)):\n",
    "            indiv[start:start+bit[i]] = encode_to_gen(param[i], bit[i])\n",
    "            start += bit[i]\n",
    "        \n",
    "        return indiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Get model \n",
    "    def individual_model(indiv, num_class): \n",
    "        input_shape=(indiv['input'], indiv['input'], 3)\n",
    "        model = Sequential()\n",
    "        # conv 1st\n",
    "        model.add(layer=Conv2D(indiv['filter_1'], indiv['kernel_1'], padding=indiv['padding_1'], activation=indiv['activation_1'], input_shape=input_shape))\n",
    "        if indiv['pooling_1'] == 'max':\n",
    "            model.add(layer=MaxPooling2D(indiv['pooling_size_1'][0]))\n",
    "        elif indiv['pooling_1'] == 'average':\n",
    "            model.add(layer=AveragePooling2D(indiv['pooling_size_1'][0]))\n",
    "        # conv 2nd\n",
    "        model.add(layer=Conv2D(indiv['filter_2'], indiv['kernel_2'], padding=indiv['padding_2'], activation=indiv['activation_2']))\n",
    "        if indiv['pooling_2'] == 'max':\n",
    "            model.add(layer=MaxPooling2D(indiv['pooling_size_2'][0]))\n",
    "        elif indiv['pooling_2'] == 'average':\n",
    "            model.add(layer=AveragePooling2D(indiv['pooling_size_2'][0]))\n",
    "        # conv 3th\n",
    "        model.add(layer=Conv2D(indiv['filter_3'], indiv['kernel_3'], padding=indiv['padding_3'], activation=indiv['activation_3']))\n",
    "        if indiv['pooling_3'] == 'max':\n",
    "            model.add(layer=MaxPooling2D(indiv['pooling_size_3'][0]))\n",
    "        elif indiv['pooling_3'] == 'average':\n",
    "            model.add(layer=AveragePooling2D(indiv['pooling_size_3'][0]))\n",
    "        # dense layer\n",
    "        model.add(layer=Flatten())\n",
    "        model.add(layer=Dropout(indiv['dropout_1']))\n",
    "        model.add(layer=Dense(indiv['dense_1'], activation=indiv['activation_4']))\n",
    "        model.add(layer=Dense(num_class, activation=indiv['activation_5']))\n",
    "\n",
    "        # plot_model(model, to_file='images/model_plot_{}.png'.format(index_p), show_shapes=True, show_layer_names=True)\n",
    "        # choose type to optimizer\n",
    "        if indiv['optimizer'] == 'adam':\n",
    "            opt = Adam(lr=indiv['learn_rate'], decay=indiv['learn_rate']/ indiv['epoch'])\n",
    "        else:\n",
    "            opt = Adamax(lr=indiv['learn_rate'], decay=indiv['learn_rate']/ indiv['epoch'])\n",
    "        model.compile(optimizer=opt, loss=indiv['loss_func'], metrics=['accuracy'])\n",
    "        \n",
    "        # construct the training image generator for data augmentation\n",
    "        aug = ImageDataGenerator(\n",
    "            rotation_range=40,\n",
    "            zoom_range=0.15,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            shear_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            fill_mode=\"nearest\")\n",
    "        # train the head of the network\n",
    "\n",
    "        x_train, x_test, y_train, y_test = mask_detect(input_shape[:2])\n",
    "\n",
    "        print(\"[INFO] training head...\")\n",
    "        H = model.fit(\n",
    "            aug.flow(x_train, y_train, batch_size=indiv['batch']),\n",
    "            steps_per_epoch=len(x_train) // indiv['batch'],\n",
    "            validation_data=(x_test, y_test),\n",
    "            validation_steps=len(x_test) // indiv['batch'],\n",
    "            epochs=indiv['epoch'])\n",
    "\n",
    "        fitness = model.evaluate(x=x_test, y=y_test, verbose=0)[1]\n",
    "        return fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def individual_decode(binary_gen):\n",
    "        input_size = [70, 120, 170, 220]\n",
    "        batch = [10, 15, 20, 25]\n",
    "        kernel_size = [(3, 3), (5, 5)]\n",
    "        pooling = ['max', 'average']\n",
    "        pooling_size = [(2, 2), (3, 3)]\n",
    "        activation = ['sigmoid', 'relu']\n",
    "        padding = ['valid', 'same']\n",
    "        dropout = [0.1, 0.2, 0.3, 0.4]\n",
    "        loss_func = ['categorical_crossentropy', 'binary_crossentropy']\n",
    "        learn_rate = [1e-2, 1e-3, 1e-4, 1e-5]\n",
    "        optimizer = ['adamax', 'adam']\n",
    "\n",
    "        params = {'epoch': decode_gen(binary_gen[:2]) + 5,                             \n",
    "                'input': input_size[decode_gen(binary_gen[2:4])],                 \n",
    "                'batch': batch[decode_gen(binary_gen[4:6])],                      \n",
    "                # conv 1st (8 bit)\n",
    "                'filter_1': decode_gen(binary_gen[6:9]) + 30,                 \n",
    "                'kernel_1': kernel_size[decode_gen(binary_gen[9:10])],          \n",
    "                'pooling_1': pooling[decode_gen(binary_gen[10:11])],                 \n",
    "                'pooling_size_1': pooling_size[decode_gen(binary_gen[11:12])],  \n",
    "                'activation_1': activation[decode_gen(binary_gen[12:13])],        \n",
    "                'padding_1': padding[decode_gen(binary_gen[13:14])],               \n",
    "                # conv 2nd (8 bit)\n",
    "                'filter_2': decode_gen(binary_gen[14:17]) + 60,\n",
    "                'kernel_2': kernel_size[decode_gen(binary_gen[17:18])],\n",
    "                'pooling_2': pooling[decode_gen(binary_gen[18:19])],\n",
    "                'pooling_size_2': pooling_size[decode_gen(binary_gen[19:20])],\n",
    "                'activation_2': activation[decode_gen(binary_gen[20:21])],\n",
    "                'padding_2': padding[decode_gen(binary_gen[21:22])],\n",
    "                # conv 3th (8 bit)\n",
    "                'filter_3': decode_gen(binary_gen[22:25]) + 120,\n",
    "                'kernel_3': kernel_size[decode_gen(binary_gen[25:26])],\n",
    "                'pooling_3': pooling[decode_gen(binary_gen[26:27])],\n",
    "                'pooling_size_3': pooling_size[decode_gen(binary_gen[27:28])],\n",
    "                'activation_3': activation[decode_gen(binary_gen[28:29])],\n",
    "                'padding_3': padding[decode_gen(binary_gen[29:30])],\n",
    "                # dense 1\n",
    "                # 2 bit\n",
    "                'dropout_1': dropout[decode_gen(binary_gen[30:32])],\n",
    "                # 3 bit\n",
    "                'dense_1': decode_gen(binary_gen[32:35]) + 250,\n",
    "                # 1 bit\n",
    "                'activation_4': activation[decode_gen(binary_gen[35:36])],\n",
    "                'activation_5': 'softmax',\n",
    "                # loss function, optimizer & learn rate\n",
    "                # 1 bit\n",
    "                'loss_func': loss_func[decode_gen(binary_gen[36:37])],\n",
    "                # 1 bit\n",
    "                'optimizer': optimizer[decode_gen(binary_gen[37:38])],\n",
    "                # 2 bit\n",
    "                'learn_rate': learn_rate[decode_gen(binary_gen[38:40])] \n",
    "                }\n",
    "        return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Population():\n",
    "    def __init__(self, num_individual = 10, score_func = None, \n",
    "    prob_mut = 0.2, prob_crossover = .5, num_generation = 100, \n",
    "    crossover_method = 'single', verbose = True, threshold = 1):\n",
    "\n",
    "        self.score_func = score_func\n",
    "        self.n_population = num_individual\n",
    "        self.prob_mut = prob_mut\n",
    "        self.prob_crossover = prob_crossover\n",
    "        self.population = [indiv.individual_binary() for indiv in [Individual() for _ in range(num_individual)]]\n",
    "        self.scores = []\n",
    "        self.num_generation = num_generation\n",
    "        self.best_result = None\n",
    "        self.crossover_ = crossover_method\n",
    "        self.verbose = verbose\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def eval_score(self):\n",
    "        sc = np.array([self.score_func(i) for i in self.population])\n",
    "        sc[sc <= 0] = 0.0000000001\n",
    "        return sc\n",
    "\n",
    "    def verbos_func(self, best_score, best_pop):\n",
    "        print('Num population:', self.n_population)\n",
    "        print('Current best score:',best_score)\n",
    "        print('Current best individual:', best_pop)\n",
    "        print(Individual().individual_decode(best_pop))\n",
    "        print(\"_\" * 50)\n",
    "\n",
    "    def crossover(self, one, two, method = 'single'):\n",
    "        if method == 'single':\n",
    "            pnt = np.random.randint(len(one))\n",
    "            one_temp = np.concatenate([one[0:pnt],two[pnt:]])\n",
    "            two_temp = np.concatenate([two[0:pnt], one[pnt:]])\n",
    "            return one_temp, two_temp\n",
    "\n",
    "        elif method == 'multi':\n",
    "            pnt1, pnt2 = np.random.randint(len(one), size=2)\n",
    "            if pnt1 > pnt2:\n",
    "                pnt1, pnt2 = pnt2, pnt1\n",
    "            one_temp = np.concatenate([one[0:pnt1], two[pnt1: pnt2], one[pnt2:]])\n",
    "            two_temp = np.concatenate([two[0:pnt1], one[pnt1: pnt2], two[pnt2:]])\n",
    "            return one_temp, two_temp\n",
    "        elif method == 'uniform':\n",
    "            pr = np.random.rand(len(one)) > 0.\n",
    "            one_temp = one\n",
    "            two_temp = two\n",
    "            for i in range(len(one)):\n",
    "                if pr[i]:\n",
    "                    one_temp[i], two_temp[i] = two_temp[i], one_temp[i]\n",
    "            return  one_temp, two_temp\n",
    "\n",
    "    def mutation(self, one):\n",
    "        temp_rand = np.random.randint(len(one))\n",
    "        one[temp_rand] = 1 - one[temp_rand]\n",
    "        return one\n",
    "\n",
    "    def choose(self, scores):\n",
    "        indexs = np.random.choice(np.arange(len(scores)), size = 2, p = scores/scores.sum())\n",
    "        return indexs\n",
    "\n",
    "    def inititalization(self):\n",
    "        self.population = np.array([indiv.individual_binary() for indiv in [Individual() for _ in range(self.n_population)]])\n",
    "        self.scores = self.eval_score()\n",
    "\n",
    "    def print_pop(self):\n",
    "        print('last population ', self.population)\n",
    "        print('best result ', self.best_result)\n",
    "\n",
    "    def fit(self):\n",
    "        self.inititalization()\n",
    "        best_idx = np.argsort(self.scores)[-1]\n",
    "        best_score = self.scores[best_idx]\n",
    "        best_pop = self.population[best_idx, :]\n",
    "\n",
    "        for g in range(self.num_generation):\n",
    "            if best_score >= self.threshold:\n",
    "                self.verbos_func(best_score, best_pop)\n",
    "                break\n",
    "            print(\"Generation {}:\\n\".format(g+1))\n",
    "            print(\"Individuals & Fitness: \\n{}\".format([i for i in zip(self.population, self.scores)]))\n",
    "            new_generation = []\n",
    "            for n in range(self.n_population // 2):\n",
    "                # print('dfsdf', type(self.scores))\n",
    "                i, j = self.choose(self.scores)\n",
    "\n",
    "                one = self.population[i, :].copy()\n",
    "                two = self.population[j, :].copy()\n",
    "\n",
    "                if np.random.rand() < self.prob_crossover:\n",
    "\n",
    "                    one ,two = self.crossover(one, two, self.crossover_)\n",
    "\n",
    "                if np.random.rand() < self.prob_mut:\n",
    "                    one = self.mutation(one)\n",
    "                    two = self.mutation(two)\n",
    "\n",
    "                new_generation.append(one)\n",
    "                new_generation.append(two)\n",
    "\n",
    "            self.population = np.array(new_generation)\n",
    "            self.scores = self.eval_score()\n",
    "\n",
    "            if np.max(self.scores) > best_score:\n",
    "                best_idx = np.argsort(self.scores)[-1]\n",
    "                best_score = self.scores[best_idx]\n",
    "                best_pop = self.population[best_idx, :]\n",
    "            else:\n",
    "                worst_idx = np.argsort(self.scores)[0]\n",
    "                self.population[worst_idx, :] = best_pop\n",
    "                self.scores[worst_idx] = best_score\n",
    "\n",
    "            if self.verbose:\n",
    "                self.verbos_func(best_score, best_pop)\n",
    "        self.best_result = best_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_detect(img_shape):\n",
    "    # grab the list of images in our dataset directory, then initialize\n",
    "    # the list of data (i.e., images) and class images\n",
    "    print(\"[INFO] loading images...\")\n",
    "    imagePaths = list(paths.list_images(\"data\"))\n",
    "    data = []\n",
    "    labels = []\n",
    "    # loop over the image paths\n",
    "    for imagePath in imagePaths:\n",
    "        # extract the class label from the filename\n",
    "        label = imagePath.split(os.path.sep)[-2]\n",
    "\n",
    "        # load the input image and preprocess it\n",
    "        image = load_img(imagePath, target_size=img_shape)\n",
    "        image = img_to_array(image)\n",
    "        image = preprocess_input(image)\n",
    "\n",
    "        # update the data and labels lists, respectively\n",
    "        data.append(image)\n",
    "        labels.append(label)\n",
    "\n",
    "    # convert the data and labels to NumPy arrays\n",
    "    data = np.array(data, dtype=\"float32\")\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # perform one-hot encoding on the labels\n",
    "    lb = LabelBinarizer()\n",
    "    labels = lb.fit_transform(labels)\n",
    "    labels = to_categorical(labels)\n",
    "    # partition the data into training and testing splits using 75% of\n",
    "    # the data for training and the remaining 25% for testing\n",
    "    (x_train, x_test, y_train, y_test) = train_test_split(data, labels,\n",
    "        test_size=0.20, stratify=labels, random_state=42)\n",
    "    \n",
    "    print(\"[INFO] done load...\")\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness(indiv_gen): \n",
    "    # Init fitness\n",
    "    indiv = individual_decode(indiv_gen)\n",
    "\n",
    "    fitness_indi = individual_model(indiv=indiv, num_class=2)\n",
    "\n",
    "    # print('Accuracy: {}'.format(fitness_indi * 100))\n",
    "    return fitness_indi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_individual = 2     # Number of individual\n",
    "n_generation = 1     # Number of generation\n",
    "threshold = 0.994    # Threshold\n",
    "\n",
    "model = Population(num_generation=n_generation, \n",
    "                    num_individual=n_individual, \n",
    "                    score_func=fitness, \n",
    "                    prob_crossover=.8, \n",
    "                    prob_mut=.3, \n",
    "                    crossover_method='uniform',\n",
    "                    threshold=threshold)\n",
    "model.fit()"
   ]
  }
 ]
}